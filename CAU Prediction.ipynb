{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import encoder and decoder model\n",
    "from cau_prediction import Encoder,Decoder\n",
    "from cau_prediction import cal_conv_out_size\n",
    "from utils import unpack_music_features,load_data,get_song_idx,get_song_info,load_CAU_dict,get_beat_of_cau,align_cau_gt,align_cau_gen"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_beat_of_cau(cau_file,cau_idx_to_name,cau_name,idx=False):\n",
    "    if cau_name in ('HOLD','SOD','EOD','NIL',41,42,43,44):\n",
    "        beat = 4\n",
    "    elif idx== True:\n",
    "        beat = cau_file.loc[cau_file['movement_tag'] == cau_idx_to_name[cau_name+1], 'beats'].values[0]\n",
    "    else:\n",
    "        beat =  cau_file.loc[cau_file['movement_tag'] == cau_name, 'beats'].values[0]\n",
    "    return beat\n",
    "\n",
    "def align_cau_gen(song_len, cau_seq, prob_seq):\n",
    "    \n",
    "    aligned_cau_gen = []\n",
    "    aligned_prob_gen = []\n",
    "    \n",
    "    beat_idx = 0\n",
    "    for i in range(len(cau_seq)):\n",
    "        cau = cau_seq[i]\n",
    "        prob = prob_seq[i]\n",
    "        beats_len = get_beat_of_cau(cau_file,cau_idx_to_name,cau,True) * interval\n",
    "        for j in range(int(beat_idx),int(beat_idx+beats_len)):\n",
    "            if j < song_len:\n",
    "                aligned_cau_gen.append(cau)\n",
    "                aligned_prob_gen.append(prob)\n",
    "            else:\n",
    "                break\n",
    "        beat_idx+=beats_len\n",
    "    for blanks in range(int(beat_idx),song_len):\n",
    "        aligned_cau_gen.append(41)\n",
    "        aligned_prob_gen.append(torch.zeros(45))\n",
    "    return aligned_cau_gen,aligned_prob_gen\n",
    "\n",
    "def align_cau_gt(song_len, cau_seq):\n",
    "    aligned_cau_gt = []    \n",
    "    beat_idx = 0\n",
    "    for i in range(len(cau_seq)):\n",
    "        cau = cau_seq[i]\n",
    "        beats_len = get_beat_of_cau(cau_file,cau_idx_to_name,cau,True) * interval\n",
    "        for j in range(int(beat_idx),int(beat_idx+beats_len)):\n",
    "            if j < song_len:\n",
    "                aligned_cau_gt.append(cau)\n",
    "            else:\n",
    "                break\n",
    "        beat_idx+=beats_len\n",
    "    for blanks in range(int(beat_idx),song_len):\n",
    "        aligned_cau_gt.append(41)\n",
    "    return aligned_cau_gt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_chroma_interval(chroma,t,chroma_len=200):\n",
    "    t=int(t/10)\n",
    "    chroma_train = chroma[int(t)-int(chroma_len/2):int(t)+int(chroma_len/2)]\n",
    "    chroma_train = torch.from_numpy(chroma_train)\n",
    "    chroma_train = chroma_train.reshape(12,chroma_len).unsqueeze(0)\n",
    "    return chroma_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_beat_note_interval(beat_note,t,beat_note_len=2000):\n",
    "    t = int(t)\n",
    "    beat_note_train = beat_note[int(t)-int(beat_note_len/2):int(t)+int(beat_note_len/2)]\n",
    "    beat_note_train = torch.from_numpy(beat_note_train)\n",
    "    beat_note_train = beat_note_train.reshape(2,beat_note_len).unsqueeze(0)\n",
    "    return beat_note_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Encoder_Decoder(nn.Module):\n",
    "    def __init__(self, encoder,decoder,sliding_window_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sliding_window_size = sliding_window_size\n",
    "        \n",
    "    def forward(self,chroma,beat_note,last_output,cau_dict,start_t,end_t,beat_interval):\n",
    "        t = start_t\n",
    "        cau_gen=[]\n",
    "        this_cau_gen = 42 #'SOD'\n",
    "        output_concat = []\n",
    "        # init hidden layer for decoder\n",
    "        hidden = decoder.init_hidden()\n",
    "        while this_cau_gen!= 43 and t + 1000 <= end_t:\n",
    "            # retrive musical features\n",
    "            chroma_interval = get_chroma_interval(chroma,t,chroma_len=200)\n",
    "            beat_note_interval = get_beat_note_interval(beat_note,t,beat_note_len=2000)\n",
    "            chroma_encoded,beat_note_encoded = self.encoder(chroma_interval.float(), beat_note_interval.float())\n",
    "            acoustic = torch.from_numpy(np.concatenate([chroma_encoded.detach().numpy(),beat_note_encoded.detach().numpy()],axis=1))\n",
    "            \n",
    "            # decoder\n",
    "            output,hidden = decoder(last_output, hidden, acoustic)\n",
    "            cau_id = np.argmax(np.exp(output.detach().numpy()))\n",
    "            this_cau_gen = cau_id\n",
    "            \n",
    "            # update t, output and save generated CAU sequence\n",
    "            cau_gen.append(this_cau_gen)\n",
    "            t += get_beat_of_cau(cau_file,cau_idx_to_name,this_cau_gen,True) * beat_interval\n",
    "            last_output = torch.from_numpy(np.array(int(this_cau_gen)))\n",
    "            output_concat.append(np.exp(output.detach().numpy()))\n",
    "        return cau_gen,output_concat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Tuning parameters:\n",
    "* sliding_window_size\n",
    "* out_len of musical features\n",
    "* learning rate\n",
    "* dropout rate\n",
    "* optimizer (RMSProp)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "out_len = 30\n",
    "encoder = Encoder(chroma_len=200, beat_note_len=2000, out_len=out_len, dropout_p=0.2)\n",
    "decoder = Decoder(hidden_size=128, output_size=45, acoustic_size=out_len*2, dropout_p=0.2)\n",
    "model = Encoder_Decoder(encoder,decoder,sliding_window_size=1000)\n",
    "criteon = nn.NLLLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.9,patience=8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cau_file = pd.read_csv('movement_interval.csv')\n",
    "cau_idx_to_name,cau_name_to_idx = load_CAU_dict('C')\n",
    "genre = 'C'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_for epoch in range(epochs):\n",
    "    genre='C'\n",
    "    for dance_idx in (get_song_idx(genre)[1]):\n",
    "#         print('==> Training',genre,dance_idx)\n",
    "        # load features\n",
    "        chroma_vector,beat_vector,onset_vector = unpack_music_features('./music_features/',genre,dance_idx+1)\n",
    "        beat_note_vector = np.concatenate([beat_vector.reshape(-1,1),onset_vector.reshape(-1,1)],axis=1)\n",
    "        last_output = torch.from_numpy(np.array(44))\n",
    "        dance_name, _, gt_cau, start_pos, end_pos, interval = get_song_info(cau_file,cau_idx_to_name,genre,dance_idx)\n",
    "        song_len = beat_vector.shape[0]\n",
    "        cau_gen,prob_gen = model(chroma=chroma_vector,\n",
    "                               beat_note=beat_note_vector,\n",
    "                               last_output=last_output,\n",
    "                               cau_dict=cau_name_to_idx,\n",
    "                               start_t = 1000,\n",
    "                               end_t = song_len,\n",
    "                               beat_interval = interval)\n",
    "        cau_gen = np.array(cau_gen)\n",
    "        print(cau_gen)\n",
    "        prob_gen = torch.from_numpy(np.array(prob_gen).reshape(len(cau_gen),45))\n",
    "        aligned_cau_gen,aligned_prob_gen = align_cau_gen(song_len, cau_gen, prob_gen)\n",
    "        aligned_prob_gen = np.array([t.numpy() for t in aligned_prob_gen]).reshape(len(aligned_cau_gen),45)\n",
    "        aligned_prob_gen = torch.tensor(aligned_prob_gen,requires_grad=True)\n",
    "        \n",
    "        # prep ground truth\n",
    "        gt_cau = [cau_name_to_idx[cau] for cau in gt_cau]\n",
    "        aligned_gt_cau = align_cau_gt(song_len,gt_cau)\n",
    "        aligned_gt_cau = torch.from_numpy(np.array(aligned_gt_cau)) \n",
    "                \n",
    "        # loss\n",
    "        loss = criteon(aligned_prob_gen,aligned_gt_cau)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        print('== Epoch',epoch,'==','Loss', loss.item())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "6007dfe94dbaeacc9bdde5ddb39667255d3ded318ca74fee2930cc1a845c26d1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
